{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-05T13:14:45.810630Z","iopub.execute_input":"2021-11-05T13:14:45.810988Z","iopub.status.idle":"2021-11-05T13:14:45.819987Z","shell.execute_reply.started":"2021-11-05T13:14:45.810949Z","shell.execute_reply":"2021-11-05T13:14:45.819195Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport os\n\nfrom PIL import Image\n\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\n\nimport torch.nn as nn\nimport torchvision.models as models\nimport torch.optim as optim\nimport torchvision.transforms as transforms","metadata":{"execution":{"iopub.status.busy":"2021-11-05T12:22:26.422395Z","iopub.execute_input":"2021-11-05T12:22:26.422688Z","iopub.status.idle":"2021-11-05T12:22:28.108414Z","shell.execute_reply.started":"2021-11-05T12:22:26.422656Z","shell.execute_reply":"2021-11-05T12:22:28.107687Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class PawpularDataset(Dataset):\n    def __init__(self, images_path, features_path, transform):\n        self.images_path = images_path\n        self.df = pd.read_csv(features_path, dtype={'Pawpularity': np.float32})\n        \n        self.imgs = self.df['Id']\n        self.targets = self.df['Pawpularity']\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        img_id = self.imgs[index]\n        img = Image.open(os.path.join(self.images_path, img_id+'.jpg')).convert('RGB')\n        img = self.transform(img)\n        \n        targets = self.targets[index]\n        \n        return img, targets","metadata":{"execution":{"iopub.status.busy":"2021-11-05T12:22:31.039393Z","iopub.execute_input":"2021-11-05T12:22:31.039900Z","iopub.status.idle":"2021-11-05T12:22:31.047366Z","shell.execute_reply.started":"2021-11-05T12:22:31.039863Z","shell.execute_reply":"2021-11-05T12:22:31.046642Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class PawpularDatasetTest(Dataset):\n    def __init__(self, images_path, features_path, transform):\n        self.images_path = images_path\n        self.df = pd.read_csv(features_path)\n        \n        self.imgs = self.df['Id']\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        img_id = self.imgs[index]\n        img = Image.open(os.path.join(self.images_path, img_id+'.jpg')).convert('RGB')\n        img = self.transform(img)\n        \n        return img","metadata":{"execution":{"iopub.status.busy":"2021-11-05T12:51:33.292352Z","iopub.execute_input":"2021-11-05T12:51:33.292609Z","iopub.status.idle":"2021-11-05T12:51:33.299516Z","shell.execute_reply.started":"2021-11-05T12:51:33.292581Z","shell.execute_reply":"2021-11-05T12:51:33.298781Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"class PretrainedCNN(nn.Module):\n    def __init__(self, hidden_size, num_classes, train=False):\n        super(PretrainedCNN, self).__init__()\n        self.train = train\n        self.resnet = models.resnet18(pretrained=True) # TODO\n        \n        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, hidden_size) # TODO\n        \n        self.fc = nn.Linear(hidden_size, num_classes)\n        \n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(0.2)\n        \n    def forward(self, images):\n        for name, param in self.resnet.named_parameters():\n            if 'fc.weight' in name or 'fc.bias' in name:\n                param.requires_grad = True\n            else:\n                param.requires_grad = self.train\n                \n        resnet_features = self.dropout(self.relu(self.resnet(images)))\n                \n        return self.fc(resnet_features)","metadata":{"execution":{"iopub.status.busy":"2021-11-05T12:22:35.110603Z","iopub.execute_input":"2021-11-05T12:22:35.111270Z","iopub.status.idle":"2021-11-05T12:22:35.119428Z","shell.execute_reply.started":"2021-11-05T12:22:35.111235Z","shell.execute_reply":"2021-11-05T12:22:35.118434Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose(\n  [\n   transforms.Resize((256,256)),\n   transforms.CenterCrop(224),\n   transforms.ToTensor(),\n   transforms.Normalize(mean=[0.485, 0.456, 0.406], \n                        std=[0.229, 0.224, 0.225])\n  ]\n)","metadata":{"execution":{"iopub.status.busy":"2021-11-05T12:22:38.660190Z","iopub.execute_input":"2021-11-05T12:22:38.660450Z","iopub.status.idle":"2021-11-05T12:22:38.665420Z","shell.execute_reply.started":"2021-11-05T12:22:38.660422Z","shell.execute_reply":"2021-11-05T12:22:38.664565Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"torch.manual_seed(1)\n\ntrainset = PawpularDataset(images_path='../input/petfinder-pawpularity-score/train', \n                           features_path='../input/petfinder-pawpularity-score/train.csv', \n                           transform=transform)\n\n\ntestloader = PawpularDatasetTest(images_path='../input/petfinder-pawpularity-score/test', \n                           features_path='../input/petfinder-pawpularity-score/test.csv', \n                           transform=transform)\n\ntrain_loader = DataLoader(\n    dataset=trainset,\n    batch_size=64,\n    shuffle=True\n)\n\ntest_loader = DataLoader(\n    dataset=testloader,\n    batch_size=64,\n    shuffle=False\n)\n\nnum_examples = len(trainset)\nval_len = round(0.33*num_examples)\ntrain_len = num_examples - val_len\n\ntrain, validation = torch.utils.data.random_split(trainset, [train_len, val_len])\ntrain_loader = torch.utils.data.DataLoader(train, batch_size=100, \n                                           shuffle=True, num_workers=2)\nval_loader = torch.utils.data.DataLoader(validation, batch_size=100, \n                                         shuffle=True, num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2021-11-05T13:02:12.738711Z","iopub.execute_input":"2021-11-05T13:02:12.739293Z","iopub.status.idle":"2021-11-05T13:02:12.769452Z","shell.execute_reply.started":"2021-11-05T13:02:12.739251Z","shell.execute_reply":"2021-11-05T13:02:12.768645Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nhidden_size = 256\nnum_classes = 1\nlearning_rate = 3e-4\nnum_epochs = 5","metadata":{"execution":{"iopub.status.busy":"2021-11-05T12:22:49.906272Z","iopub.execute_input":"2021-11-05T12:22:49.906792Z","iopub.status.idle":"2021-11-05T12:22:49.960160Z","shell.execute_reply.started":"2021-11-05T12:22:49.906724Z","shell.execute_reply":"2021-11-05T12:22:49.959180Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"torch.manual_seed(101)\n\nlosses = list()\nmodel = PretrainedCNN(hidden_size, num_classes).to(device)\n\ncriterion = nn.MSELoss()\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\nfor epoch in range(1, num_epochs+1):\n    \n    for step, (img, target) in enumerate(train_loader):\n\n        model.zero_grad()\n\n        img = img.to(device)\n        target = target.to(device)\n\n        outputs = model(img)\n\n        loss = criterion(outputs, target.unsqueeze(1))\n\n        loss.backward()\n        optimizer.step()\n\n        losses.append(loss.item())\n        stats = 'Epoch [%d/%d], Step [%d], Loss: %.4f' % (epoch, num_epochs, step, loss.item())\n        print('\\r' + stats, end='')\n        \n    with torch.no_grad():\n        val_losses = 0\n        for img, target in val_loader:\n            img = img.to(device)\n            target = target.to(device)\n            \n            outputs = model(img)\n            val_loss = criterion(outputs, target.unsqueeze(1))\n            val_losses += (1/len(val_loader))*val_loss.item()\n            \n        print('\\n Epoch [%d/%d], Val Loss: %.4f' % (epoch, num_epochs, val_losses))","metadata":{"execution":{"iopub.status.busy":"2021-11-05T12:22:52.778094Z","iopub.execute_input":"2021-11-05T12:22:52.778549Z","iopub.status.idle":"2021-11-05T12:45:09.074130Z","shell.execute_reply.started":"2021-11-05T12:22:52.778514Z","shell.execute_reply":"2021-11-05T12:45:09.073178Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"with torch.no_grad():\n    for images in test_loader:\n        images = images.to(device)\n        outputs = model(images)","metadata":{"execution":{"iopub.status.busy":"2021-11-05T13:03:27.274845Z","iopub.execute_input":"2021-11-05T13:03:27.275435Z","iopub.status.idle":"2021-11-05T13:03:27.311399Z","shell.execute_reply.started":"2021-11-05T13:03:27.275399Z","shell.execute_reply":"2021-11-05T13:03:27.310669Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"data_test = pd.read_csv('/kaggle/input/petfinder-pawpularity-score/test.csv')","metadata":{"execution":{"iopub.status.busy":"2021-11-05T13:05:22.221311Z","iopub.execute_input":"2021-11-05T13:05:22.221571Z","iopub.status.idle":"2021-11-05T13:05:22.231065Z","shell.execute_reply.started":"2021-11-05T13:05:22.221543Z","shell.execute_reply":"2021-11-05T13:05:22.230158Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"outputs.squeeze(1).cpu()","metadata":{"execution":{"iopub.status.busy":"2021-11-05T13:08:38.138569Z","iopub.execute_input":"2021-11-05T13:08:38.140247Z","iopub.status.idle":"2021-11-05T13:08:38.151794Z","shell.execute_reply.started":"2021-11-05T13:08:38.140200Z","shell.execute_reply":"2021-11-05T13:08:38.149288Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"sub = (pd.DataFrame({'Id': data_test['Id'].values, 'Pawpularity': outputs.squeeze(1).cpu()}))\nsub","metadata":{"execution":{"iopub.status.busy":"2021-11-05T13:08:47.967341Z","iopub.execute_input":"2021-11-05T13:08:47.968190Z","iopub.status.idle":"2021-11-05T13:08:47.984943Z","shell.execute_reply.started":"2021-11-05T13:08:47.968153Z","shell.execute_reply":"2021-11-05T13:08:47.984001Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"sub.to_csv('submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-11-05T13:08:59.854360Z","iopub.execute_input":"2021-11-05T13:08:59.854991Z","iopub.status.idle":"2021-11-05T13:08:59.862373Z","shell.execute_reply.started":"2021-11-05T13:08:59.854947Z","shell.execute_reply":"2021-11-05T13:08:59.861520Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}